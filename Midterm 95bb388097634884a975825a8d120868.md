# Midterm

Urgency: Low
Deadline: August 25, 2023
Status: Done
Time left: â—€ï¸Ž 62D

# Intermediary meeting (Info)

By the middle of the Master thesis, the student, the supervisor of the Master thesis and the designated representative of the Biomedicine Commission meet for an intermediary discussion. The topics of this discussion are the **accomplished course work and a brief presentation on the results collected** by mid-term of the Master thesis. The student, the responsible supervisor listed on the Learning Agreement, possibly the direct supervisor and the responsible person of the 'Biomedicine Commission' (coach) are invited to this meeting.

Will be over zoom with V. Kurtcuoglu

Duration: 40 minutes

Presentation: 10 minutes at start (Methods and Results so far)

## Date

25.8.23 - 13:00 (Fri)

## To Present

### Methods = Progress

### Results = Analysis

<aside>
ðŸ”Ž I have created an analysis section with my EDA so far. 
(Collapse `Progress` if open)

</aside>

### Project Description

Genomic copy number variations (CNV) are a major contributor to the mutation load in cancer. The generation of reference cancer CNV datasets and large-scale CNV data analyses constitute a focus of the Theoretical Cytogenetics and Oncogenomics group. Such analyses are complementary to studies focussing on sequence modifications (e.g. SNVs) detected through NGS techniques.

The study will generate compound variant data through integration of the Progenetix reference CNV data with SNVs from external datasets, most notably from the Cancer Genome Atlas (TCGA; ~11k samples with -omics data), cancer cell lines (cancercelllines.org) and data portals such as cBioPortal.

- Comprehensive integration of non-CNV genomic variation data with Progenetix
- Creation of a GA4GH Beacon w/ deep representation of TCGA (and cell line) data
- Development of Beacon queries and representation for compound genomic variations
- Analysis of compound or alternative variant events in the TCGA dataset and beyond

---

# Presentation

### Methods (Progess)

************Mining************

- Present TCGA GDC data set
- ( with ClinVar and PCAWG?)

********************Processing********************

- Progenetix import:
    - Gathering needed information for import
    - Retrieving Sample IDâ€™s from aliquot barcodes
    - Conversion of the â€˜1-start, fully-closedâ€™ into a â€˜0-start, half-openâ€™ genomic coordinate system
    - Adding sequence ontology terms

### Results (Analysis)

- Descriptives about data set

# Progress

---

## Workflow

The workflow looks like this so far:

### Code

### Workflow

```python
# This rule executes all the code except the Novel Data Download
rule targets:
	input:
		"temp/maf_data.csv",
		"temp/mapfile.tsv",
		"data/varNew.tsv",
		"data/varImport.tsv"

##
## Novel Data Download
##

# Download the MAF files
rule maf_download:
	script:
		"scripts/gdc_maf_download.py"

# Unzip and move the files from the temp into the data folder
rule unpack:
	shell:
		"bash scripts/unpack.sh"

##
## If MAF files available:
##

# Concatenate all the maf files into one CSV
rule data_extraction:
	output:
		"temp/maf_data.csv"
	script:
		"scripts/data_extraction.py"

# Convert the sample barcodes to the sample ids for mapping
rule mapfile:
	input: 
		"temp/maf_data.csv"
	output: 
		"temp/mapfile.tsv"
	script:
		"scripts/aliquot_to_sample.R"

# Match the sample ids to the database to retrieve biosample ids and individual ids
# Create callset and variant ids
rule mapping:
	input:
		"temp/mapfile.tsv"
	output:
		"data/varImport.tsv",
		"data/varNew.tsv"
	script:
		"scripts/mapping_finish.py"

# Remove files in temp
rule cleanup:
    shell:
        "rm temp/*"
```

### Download

```python
#!/usr/bin/env python3
# coding: utf-8

###############################################################################

# Downloading masked somatic mutation files from the TCGA program of GDC
# Results in the download of all unrestricted MAF files 

###############################################################################
import requests
import json
import re
import os

# Access the file endpoint from GDC for id retrieval
files_endpt = "https://api.gdc.cancer.gov/files"

# Filtering for TCGA Masked Somatic Mutation
# - results in open access maf files.
# This set of filters is nested under an "and" operator.
filters = {
    "op": "and",
    "content": [
        {
            "op": "in",
            "content": {
                "field": "cases.project.program.name",
                "value": ["TCGA"]
            }
        },
        {
            "op": "in",
            "content": {
                "field": "files.data_type",
                "value": ["Masked Somatic Mutation"]
            }
        }
    ]
}

# Here a GET is used, so the filter parameters should be passed as a
# JSON string.
params = {
    "filters": json.dumps(filters),
    "fields": "file_id",
    "format": "JSON",
    "size": "20000"
}

# Download the ids
response = requests.get(files_endpt, params = params)

# Create a list for the ids
file_uuid_list = []

# This step populates the download list with the file_ids from the 
# previous query
for file_entry in json.loads(response.content.decode("utf-8"))["data"]["hits"]:
    file_uuid_list.append(file_entry["file_id"])
print("Found ", len(file_uuid_list), "files to download.")

# Import record of existing files
existing_ids = []
if os.path.isfile("data/existing_file_ids.txt"):
    with open("data/existing_file_ids.txt") as f:
        lines = f.readlines()
    for i in lines:
        existing_ids.append(i)

# Remove existing file UUIDs from download queue
removed_ids = []
for i in existing_ids:
    i = i.strip("\n")
    if i in file_uuid_list:
        file_uuid_list.remove(i)
        removed_ids.append(i)
print("Removed", len(removed_ids), "existing ids from download queue.")

# Create an empty list to store UUID chunks
ls = []

# Append sublists to "ls" for 1000 ids each (server limits)
for i in range(0, len(file_uuid_list), 1000):
    ls.append(file_uuid_list[i:i + 1000])

# Download the files
print("Starting", len(ls),"downloads...")
downloaded = 1
for idls in ls:

    # Exclude existing files
    for ids in idls:
        if ids in existing_ids:
            idls.remove(ids)
            print("Removed existing file id:", ids)
    
    data_endpt = "https://api.gdc.cancer.gov/data"

    params = {"ids": idls}

    response = requests.post(data_endpt,
                            data = json.dumps(params),
                            headers = {"Content-Type": "application/json"})

    response_head_cd = response.headers["Content-Disposition"]

    file_name = re.findall("filename=(.+)", response_head_cd)[0]

     # Check for the directory
    os.makedirs("temp/", exist_ok = True)
    save_path = "temp/"

    complete_name = os.path.join(save_path, file_name)

    with open(complete_name, "wb") as output_file:
        output_file.write(response.content)

    if len(ls) - downloaded != 0:
        print("Downloaded completed. Remaining:", len(ls) - downloaded, "of", len(ls))
        downloaded += 1
    else:
        print("Download finished")

# Create record if imported file UUIDs
for i in file_uuid_list:
    i = i + "\n"
    existing_ids.append(i)
with open("data/existing_file_ids.txt", "w") as file_ids:
    for i in existing_ids:
        file_ids.write(i)
```

### Unpacking

```bash
#!/bin/bash

# Move to directory with the downloaded data
cd temp

# Look for nested tar.gz files and extract them
find . -name '*.tar.gz' -exec tar -xzf {} \;

# Delete all tar.gz files
find . -name '*.tar.gz' -delete

# Find all directories in the current directory
for dir in */; do
    # Go into the directory
    cd "$dir" || continue

    # Look for tar.gz files and extract them
    for file in *.maf.gz; do
        gunzip "$file" || continue
    done
    
    # Move all files in the directory up one level
    mv * ../ || continue

    # Go back up to the parent directory
    cd .. || continue

    # Remove empty folder
    rmdir "$dir" || continue
done

# Check for any errors during the script execution
if [ $? -eq 0 ]; then
    echo "Script executed successfully."
else
    echo "Error occurred during script execution."
fi

cd ..

if [ ! -d "data" ]; then
    mkdir "data"
fi

if [ ! -d "data/maf_files" ]; then
    mkdir "data/maf_files"
fi

mv temp/*.maf data/maf_files
```

### Data extraction

```python
#!/usr/bin/env python3
# coding: utf-8

#####################################################################

# Data extraction from MAF files
# All information will be stored at data/maf_data.csv

#####################################################################

# Module import
import pandas as pd
import os
import shutil
import glob
from tqdm import tqdm

# Create a dataframe and a list for the MAF data
data = pd.DataFrame()
df_list = []

# Information to be extracted for variant import
relevant_columns = ["Tumor_Sample_UUID", "Matched_Norm_Sample_UUID",
                       "case_id", "Chromosome",
                       "Start_Position", "End_Position",
                       "Variant_Classification", "Variant_Type",
                       "Reference_Allele", "Tumor_Seq_Allele2",
                       "Tumor_Sample_Barcode"]

# Iterate through directory with downloaded maf files and
# load the relevant information in "data"
print("Starting data extraction...")
for file in tqdm(glob.glob("data/maf_files/*.maf"), desc = "Extraction progress"): 
    df = pd.read_csv(file, sep = "\t", skiprows = 7, header = 0,
        low_memory = False)
    df_list.append(df[relevant_columns])

# Create one data frame from the list
data = pd.concat(df_list).reset_index(drop=True)
print("Data extraction completed.")

# Tumor Barcode shortening to get the sample barcode instead of the
# aliquot barcode (first 16 characters = sample barcode)
data["aliquot_barcode"] = data["Tumor_Sample_Barcode"]
data["Tumor_Sample_Barcode"] = data["Tumor_Sample_Barcode"].str.slice(stop = 16)

 # Check for the directory
os.makedirs("temp/", exist_ok = True)
print("Writing output file...")
# and create .csv file in the directory
data.to_csv("temp/maf_data.csv", index = False)
print("Done.")
```

### Converting

```r
#####################################################################

# Turning barcodes into Sample UUIDs for mapping in progenetix

#####################################################################

# Load necessary libraries
suppressPackageStartupMessages(library(tidyverse))
library(TCGAutils)

# Import data frame and extract barcodes
cat("Loading data...\n")
data <- read_csv("temp/maf_data.csv", show_col_types = FALSE)

sample_barcodes <- unique(data["Tumor_Sample_Barcode"])

# Create an empty list for the ids
sample_ids <- list()

# Convert barcodes into ids
cat("Converting aliquot UUID to sample UUID...\n")
for (id in sample_barcodes){
  sam <- barcodeToUUID(id)
  sam <- sam$sample_ids
  sample_ids <- c(sample_ids, sam)
}

# Make a data frame for mapping
mapping_df <- data.frame(unlist(as.list(sample_barcodes)), unlist(sample_ids))
colnames(mapping_df) <- c("sample_barcode", "sample_ids")

# Join the two data frames based on matching Barcodes
mapfile <- left_join(data, mapping_df,
                     by = c("Tumor_Sample_Barcode" = "sample_barcode"))

cat("Converting completed.\n")

#####################################################################

# Renaming for further processing

#####################################################################

# Rename the columns
colnames(mapfile) <- c("aliquot_id", "reference_id", "case_id", "chromosome",
                       "start", "end", "variant_classification", "variant_type",
                       "reference_bases", "alternate_bases", "sample_barcode",
                       "aliquot_barcode", "sample_id")

# Select important ones and rearrange
mapfile <- mapfile %>% select(case_id, sample_id, aliquot_id,
                              reference_id, chromosome, start, end,
                              variant_classification, variant_type,
                              reference_bases, alternate_bases)

cat("Writing output file...\n")
# Write file
write_tsv(mapfile, "temp/mapfile.tsv")

cat("Done\n")
```

### Mapping

```python
#!/usr/bin/env python3
# coding: utf-8

#####################################################################

# Preparation for variant import to progenetix

#####################################################################

import os
import pandas as pd
from bycon import *
from pymongo import MongoClient
from tqdm import tqdm
import numpy as np

# Connect to MongoDB
client = MongoClient()
db = client.progenetix
bs = db.biosamples

# Read the data frame
df = pd.read_csv("temp/mapfile.tsv", sep = "\t",
    header = 0, low_memory = False)

print("Preparation for mapping...")
# Create legacy ids / external references
df["case_id"] = "pgx:TCGA." + df["case_id"]
df["sample_id"] = "pgx:TCGA." + df["sample_id"]

# Create placeholder for variant id, gets created while import
df["variant_id"] = [" "] * len(df)

# Naming convention from progenetix
df["snv_type"] = df["variant_type"]
df["reference_name"] = df["chromosome"].str.slice(start=3)
df.loc[df["reference_bases"] == "-", "reference_bases"] = "."
df.loc[df["alternate_bases"] == "-", "alternate_bases"] = "."

# Adding sequence ontologies - http://www.sequenceontology.org/browser/
df["variant_state_id"] = ["SO:0001059"] * len(df)
df.loc[df["variant_type"] == "SNP", "specific_so"] = "SO:0001483"
df.loc[df["variant_type"] == "DNP", "specific_so"] = "SO:0002007"
df.loc[df["variant_type"] == "TNP", "specific_so"] = "SO:0002007"
df.loc[df["variant_type"] == "ONP", "specific_so"] = "SO:0002007"
df.loc[df["variant_type"] == "DEL", "specific_so"] = "SO:0000159"
df.loc[df["variant_type"] == "INS", "specific_so"] = "SO:0000667"

# Convert 1-based MAF files to 0-based
# Explanation @ https://www.biostars.org/p/84686/
df.loc[df["variant_type"].isin(["SNP", "DNP", "TNP", "ONP", "DEL"]), "start"] -= 1
df.loc[df["variant_type"] == "INS", "end"] -= 1

# Generate callset_ids per aliquot for import and map sample_id to biosample_id
print("Starting progenetix mapping...")

biosample_mapping = {}

for aliquot in tqdm(set(df["aliquot_id"])):

    sample_id = df.loc[df["aliquot_id"] == aliquot, "sample_id"].iloc[0]

    if sample_id not in biosample_mapping:
        hit = bs.find({"external_references.id": {"$regex": sample_id},
                        "biosample_status.id": "EFO:0009656"})

        for entry in hit:
            biosample_mapping[sample_id] = (entry["id"], entry["individual_id"])

            break

    biosample_id, individual_id = biosample_mapping.get(sample_id, ("", ""))

    cs_id = generate_id("pgxcs")

    df.loc[df["aliquot_id"] == aliquot,
        ["callset_id", "biosample_id", "individual_id"]] = cs_id, biosample_id, individual_id

print("Mapping completed\nWriting files...")
# Clean up
df = df[["biosample_id", "variant_id", "callset_id", "individual_id",
    "reference_name", "start", "end", "reference_bases",
    "alternate_bases", "variant_classification", "variant_state_id",
    "specific_so", "aliquot_id", "reference_id", "case_id",
    "sample_id", "snv_type"]]

df = df.replace("", np.nan)
variants_in_db = df.dropna(subset = ["biosample_id"])
new = df[df["biosample_id"].isna()]

# Write finished mapping file
os.makedirs("data/", exist_ok = True) # Check for the directory
variants_in_db.to_csv("data/varImport.tsv", sep = "\t", index = False)  # and create .tsv file in the directory
new.to_csv("data/varNew.tsv", sep = "\t", index = False)

print("Done.\n- Variants ready for import: /data/varImport.tsv\n- New variant data: data/varNew.tsv")
```

## Function

****Novel data****

****************Download****************

Modules: requests, json, re, os

The workflow is able to search for mutation annotation format (MAF) files for masked somatic mutations from TCGA program in the NIC/GDC database and download all files. The download happens in chunks of 1000 files, so the server does not time out. With this a file is created to keep track of the downloaded files. This file is read within a new run of the download code and will exclude files that are already present.

**********Unpacking zip files**********

Modules: 

Afterwards, all the downloads are unpacked until the MAF files and then stored in the data directory in the maf_files folder and empty directories are deleted for cleanliness.

**************************************MAF files available**************************************

******************************Data extraction******************************

Modules: pandas, os, glob, tqdm

*For future use it should be possible to load MAF files into the same directory and the workflow will extract the information from the files and store them together in a file called maf_data.csv. If there is already data available from previous imports, it will be read in and the new data will be compared to the existing, so only additional data will get loaded into the CSV.* ****(Not there yet. Necessary?)****

The extraction script will load in the MAF files stored in the `data/maf_files/` directory and store the following columns in a data frame, that will be put in a list of data frames, which will be put together in the end. The relevant columns are:

- Tumor_Sample_UUID
    - GDC aliquot UUID for tumor sample
- Matched_Norm_Sample_UUID
    - GDC aliquot UUID for matched normal sample
- case_id
    - GDC UUID for the case
- Chromosome
    - The affected chromosome (e.g., chr1)
- Start_Position
    - Lowest numeric position of the reported variant on the genomic reference sequence. Mutation start coordinate
- End_Position
    - Highest numeric genomic position of the reported variant on the genomic reference sequence. Mutation end coordinate
- Variant_Classification
    - Translational effect of variant allele
- Variant_Type
    - Type of mutation. TNP (tri-nucleotide polymorphism) is analogous to DNP (di-nucleotide polymorphism) but for three consecutive nucleotides. ONP (oligo-nucleotide polymorphism) is analogous to TNP but for consecutive runs of four or more (SNP, DNP, TNP, ONP, INS, DEL, or Consolidated)
- Reference_Allele
    - The plus strand reference allele at this position. Includes the deleted sequence for a deletion or "-" for an insertion.
- Tumor_Seq_Allele2
    - Tumor sequencing (discovery) allele 2 - ***Tumor_Seq_Allele1 is always the same as the Reference_Allele***
- Tumor_Sample_Barcode
    - Aliquot barcode for the tumor sample

During the extraction the variable â€œTumor_Sample_Barcodeâ€ will be labeled correctly as â€œaliquot_barcodeâ€, since the given barcode belongs to an aliquot of a sample, and only the first 16 characters are kept as sample barcode. (Hierarchy in GDC Data Portal: Samples > Portions > Analytes > Aliquots)

********************Conversion********************

Modules: tidyverse, TCGAutils

With the package â€˜TCGAutilsâ€™ it is possible to convert barcodes to UUIDs, which is used to obtain the original sample id. This is needed since in progenetix the sample id is used instead of the aliquot id. Furthermore, the columns are renamed to match the variable names used in the bycon package variant import script. Lastly, the temporary file mapfile.tsv is created in the temp directory. The columns kept are:

- case_id
- sample_id
- aliquot_id
- reference_id
- chromosome
- start
- end
- variant_classification
- variant_type

**************Mapping**************

Modules: os, pandas, bycon, pymongo, tqdm, numpy

During the mapping process, the file created beforehand will be loaded and several conventions from progenetix will be applied:

1. The case and sample ids will get the prefix â€˜pgx:TCGA.â€™
2. â€˜variant_typeâ€™ is renamed in â€˜snv_typeâ€™
3. â€˜chromosomeâ€™ is renamed into â€˜reference_nameâ€™ and the â€˜chrâ€™ prefix is discarded
4. The sequence ontology for sequence alteration (SO:0001059) is used to label all variants as SNVs - [http://www.sequenceontology.org/browser/](http://www.sequenceontology.org/browser/)
5. Each SNV gets the sequence ontology for its specific type:
- Single nucleotide polymorphisms (SNP): SO:0001483
- Multiple nucleotide polymorphisms (MNP): SO:0002007 (include DNPs, TNPs, ONPs (â‰¥ 4))
- Deletions (DEL): SO:0000159
- Insertions (INS): SO:0000667
6. Conversion of the â€˜1-start, fully-closedâ€™ into a â€˜0-start, half-openâ€™ genomic coordinate system as recommended by the global alliance for genomics and health ([GA4GH](http://ga4gh.org)) - [https://genomestandards.org/standards/genome-coordinates/](https://genomestandards.org/standards/genome-coordinates/). This is achieved by:
- Subtracting the value 1 of the â€˜startâ€™ variable for SNPs, MNPs, and DELs
- Subtracting the value 1 of the â€˜endâ€™ variable for INSs
For a more detailed explanation see below.

Then the sample ids are taken from a set of unique aliquot ids and mapped to the progenetix data base, where the internal biosample id and individual id is retrieved, if the sample id is in the data base. Additionally, an internal callset id is generated and added for each unique aliquot id. The generated and the retrieved variables are then assigned to the corresponding aliquot id.

In the end, the variants that couldnâ€™t be mapped to a sample id will be labeled as new variants and stored in a separate file. The variants ready to be imported and the new variants will be stored as a TSV in the data directory with the following format:

| biosample_id | variant_id | callset_id | individual_id | reference_name | start | end | reference_bases | alternate_bases | variant_classification | variant_state_id | specific_so | aliquot_id | reference_id | case_id | sample_id | variant_types |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |

With this the format for the database import is given and the data can be import into the progenetix MongoDB.

---

Additional explanation for the genomic coordinate system:

![[https://www.biostars.org/p/84686/](https://www.biostars.org/p/84686/)](Midterm%2095bb388097634884a975825a8d120868/Screenshot_2023-06-16_at_15.20.08.png)

[https://www.biostars.org/p/84686/](https://www.biostars.org/p/84686/)

## Additional work

### HGVS

There was a surprising amount of HGVS notation that did not correspond to the reference or/nor to the alternate sequence (about 50%). Effort is being made to solve that issue. The use of the hgvs Python package is intended to validate the notation. 

### COSMIC

PubMedIDs were retrieved from the COSMIC website and compared to the progenetix database to find overlaps. 

### ClinVar

ClinVar information is being retrieved with the goal to be included in the variant description in the data base.

# Analysis

# Data Preview

Collection of variables in the original data set

|  | Hugo_Symbol | Entrez_Gene_Id | Center | Chromosome | Start_Position | End_Position | Variant_Classification | Variant_Type | Reference_Allele | Tumor_Seq_Allele2 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | GLMN | 11146 | BCM | chr1 | 92246555 | 92246555 | Missense_Mutation | SNP | G | C |
| 1 | H3-3A | 3020 | BCM | chr1 | 226064454 | 226064454 | Missense_Mutation | SNP | G | C |
| 2 | HADHB | 3032 | BCM | chr2 | 26279162 | 26279162 | Missense_Mutation | SNP | A | T |
| 3 | EHD3 | 30845 | BCM | chr2 | 31266476 | 31266476 | Silent | SNP | C | A |
| 4 | VWA3B | 200403 | BCM | chr2 | 98303765 | 98303765 | Missense_Mutation | SNP | C | A |

Preview of the variables matched to progenetix

|  | biosample_id | variant_id | callset_id | individual_id | reference_name | start | end | reference_bases | alternate_bases | variant_classification | variant_state_id | specific_so | aliquot_id | reference_id | case_id | sample_id |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | pgxbs-kftvhxry |  | pgxcs-ljrfwhgg | pgxind-kftx3tgx | 1 | 92246554 | 92246555 | G | C | Missense_Mutation | SO:0001059 | SO:0001483 | d7593b2a-0d86-44aa-a404-7fd1b10f65d4 | 6934dbbc-19e6-42c3-9e9f-1db3e7b7981d | pgx:TCGA.edc62c30-cacc-457d-96ba-d05ed35432a3 | pgx:TCGA.1e6b9fc4-3fed-4d32-89b8-aa15fb4a5840 |
| 1 | pgxbs-kftvhxry |  | pgxcs-ljrfwhgg | pgxind-kftx3tgx | 1 | 226064453 | 226064454 | G | C | Missense_Mutation | SO:0001059 | SO:0001483 | d7593b2a-0d86-44aa-a404-7fd1b10f65d4 | 6934dbbc-19e6-42c3-9e9f-1db3e7b7981d | pgx:TCGA.edc62c30-cacc-457d-96ba-d05ed35432a3 | pgx:TCGA.1e6b9fc4-3fed-4d32-89b8-aa15fb4a5840 |
| 2 | pgxbs-kftvhxry |  | pgxcs-ljrfwhgg | pgxind-kftx3tgx | 2 | 26279161 | 26279162 | A | T | Missense_Mutation | SO:0001059 | SO:0001483 | d7593b2a-0d86-44aa-a404-7fd1b10f65d4 | 6934dbbc-19e6-42c3-9e9f-1db3e7b7981d | pgx:TCGA.edc62c30-cacc-457d-96ba-d05ed35432a3 | pgx:TCGA.1e6b9fc4-3fed-4d32-89b8-aa15fb4a5840 |
| 3 | pgxbs-kftvhxry |  | pgxcs-ljrfwhgg | pgxind-kftx3tgx | 2 | 31266475 | 31266476 | C | A | Silent | SO:0001059 | SO:0001483 | d7593b2a-0d86-44aa-a404-7fd1b10f65d4 | 6934dbbc-19e6-42c3-9e9f-1db3e7b7981d | pgx:TCGA.edc62c30-cacc-457d-96ba-d05ed35432a3 | pgx:TCGA.1e6b9fc4-3fed-4d32-89b8-aa15fb4a5840 |
| 4 | pgxbs-kftvhxry |  | pgxcs-ljrfwhgg | pgxind-kftx3tgx | 2 | 98303764 | 98303765 | C | A | Missense_Mutation | SO:0001059 | SO:0001483 | d7593b2a-0d86-44aa-a404-7fd1b10f65d4 | 6934dbbc-19e6-42c3-9e9f-1db3e7b7981d | pgx:TCGA.edc62c30-cacc-457d-96ba-d05ed35432a3 | pgx:TCGA.1e6b9fc4-3fed-4d32-89b8-aa15fb4a5840 |

---

# Analysis

Total variants from TCGA: 2570090

with bs_id: 2531537 (96.98%)

without bs_id: 38553 (3.02%)

Number of unique samples: 10246

With bs_id: 10003 (97.63%)

without bs_id: 243 (2.37%)

Number of unique aliquots: 10540

With bs_id: 10292 (97.65%)

without bs_id: 248 (2.35%)

---

## Most Mutated Genes

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled.png)

---

## Mutation Types & Variant Classification

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled%201.png)

### Mutation Types

Factor levels for SNVs: {'INS', 'SNP', 'ONP', 'TNP', 'DEL'}

**Total:**

SNP: 2431963 (94.6256%)

DEL: 106942 (4.161%)

INS: 31100 (1.2101%)

ONP: 70 (0.0027%)

TNP: 15 (0.0006%)

**With bs_id:**

SNP: 2395560 (94.6287%)

DEL: 105461 (4.1659%)

INS: 30432 (1.2021%)

ONP: 69 (0.0027%)

TNP: 15 (0.0006%)

**Without bs_id:**

SNP: 36403 (94.4233%)

DEL: 1481 (3.8415%)

INS: 668 (1.7327%)

ONP: 1 (0.0026%)

TNP: 0 (0.0%)

<aside>
ðŸ’¡ Percentages are around the same â†’ good representation

</aside>

### Variant Classification

|  | Total | With bs_id | 
Percentage covered
 |
| --- | --- | --- | --- |
| TOTAL | 2570090 | 2531537 | 98.5 |
| Missense_Mutation | 1583585 | 1559624 | 98.49 |
| Silent | 610315 | 601352 | 98.53 |
| Nonsense_Mutation | 128176 | 126356 | 98.58 |
| Frame_Shift_Del | 92092 | 90846 | 98.65 |
| Splice_Site | 35539 | 34897 | 98.19 |
| Frame_Shift_Ins | 28847 | 28212 | 97.8 |
| Intron | 24814 | 24447 | 98.52 |
| Splice_Region | 16707 | 16483 | 98.66 |
| RNA | 16200 | 15961 | 98.52 |
| In_Frame_Del | 8523 | 8380 | 98.32 |
| 3'UTR | 8275 | 8200 | 99.09 |
| 5'Flank | 4372 | 4307 | 98.51 |
| 5'UTR | 4129 | 4083 | 98.89 |
| 3'Flank | 3792 | 3744 | 98.73 |
| Translation_Start_Site | 2161 | 2126 | 98.38 |
| Nonstop_Mutation | 1718 | 1685 | 98.08 |
| In_Frame_Ins | 807 | 797 | 98.76 |
| IGR | 38 | 37 | 97.37 |

# Progenetix Data

## Biosamples

## Descriptive Statistics

### Histological Diagnosis:

---

Ductal Breast Carcinoma                    723
Squamous Cell Lung Carcinoma               451
Ovarian Serous Cystadenocarcinoma          386
Endometrial Endometrioid Adenocarcinoma    385
Glioblastoma                               376
...
Ovarian leiomyosarcoma                       1
Endometrial adenocarcinoma                   1
Thyroid Gland Carcinoma                      1
Liposarcoma                                  1
Large Cell Neuroendocrine Carcinoma          1
Name: histological_diagnosis_label, Length: 181, dtype: int64

### Pathological stage:

---

Stage Unknown    3628
Stage I          1138
Stage IIA         745
Stage IIB         663
Stage III         632
Stage II          603
Stage IIIA        479
Stage IV          438
Stage IB          393
Stage IA          365
Stage IVA         320
Stage IIIB        269
Stage IIIC        231
Stage IIC          67
Stage IVB          18
Stage IVC           7
Stage 0             7
Name: pathological_stage_label, dtype: int64

### ICDO Morphology:

---

Adenocarcinoma, NOS                                   1359
Squamous cell carcinoma, NOS                          1122
Infiltrating duct carcinoma, NOS                       870
Papillary adenocarcinoma, NOS                          654
Serous cystadenocarcinoma, NOS                         505
...
Liposarcoma, well differentiated                         1
Adenocarcinoma with neuroendocrine differentiation       1
Giant cell sarcoma                                       1
Aggressive fibromatosis                                  1
Large cell neuroendocrine carcinoma                      1
Name: icdo_morphology_label, Length: 138, dtype: int64

### ICDO Topography:

---

Breast, NOS         969
Kidney, NOS         715
Upper lobe, lung    566
Endometrium         530
Thyroid gland       495
...
Abdomen, NOS          1
Spinal cord           1
Border of tongue      1
Eye, NOS              1
Exocervix             1
Name: icdo_topography_label, Length: 154, dtype: int64

### Biosample:

---

neoplastic sample    10003
Name: biosample_status_label, dtype: int64

### Followup state:

---

alive (follow-up status)    6949
dead (follow-up status)     3044
no followup status            10
Name: followup_state_label, dtype: int64

### Sample Origin:

---

breast                         971
kidney                         715
upper lobe of lung             566
endometrium                    530
thyroid gland                  495
...
lesser curvature of stomach      1
abdomen                          1
somite border                    1
eye                              1
ectocervix                       1

## Graphical

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled%202.png)

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled%203.png)

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled%204.png)

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled%205.png)

![Untitled](Midterm%2095bb388097634884a975825a8d120868/Untitled%206.png)

## Individuals

- --death (3)---
alive 6889
dead 2999
not reported 2
- --ethnicity (3)---
not hispanic or latino 7239
hispanic or latino 327
not reported 2324
- --race (6)---
white 7160
not reported 1205
asian 640
black or african american 851
american indian or alaska native 25
native hawaiian or other pacific islander 9
- --label (2)---
female genotypic sex 5085
male genotypic sex 4805
- --followup_state_id (6)---
EFO:0030049 6875
alive (follow-up status) 1
EFO:0030041 3005
dead (follow-up status) 1
EFO:0030039 10
no followup status 1

## R Analysis

Variables:

- Centers
    - BCM = 339â€™308
    - BCM;BI = 3â€™779
    - BCM; WUGSC = 3â€™971
    - BI = 1â€™288â€™483
    - BI; WUGSC = 3â€™971
    - SANGER = 2â€™709
    - WUGSC = 875â€™190
- Year of birth:
    - Min = 1902; Median = 1945; Mean = 1946; Max = 1997; NAs = 53922
- Age at diagnosis:
    - min = 14.43; median = 63.36; mean = 62.45; max = 90.06; NAs = 48227
- Days to death:
    - Min = 0; Median = 603; Mean = 1012; Max = 10870; NAs = 1â€™818â€™803
- Sex:
    - Female genotypic sex = 1â€™452â€™573
    - Male genotypic sex = 1â€™079â€™010
- Race:
    - American indian or alaska native = 5â€™110
    - Asian = 174â€™350
    - Black or african american = 191â€™575
    - Native hawaiian or other pacific islander = 11â€™975
    - Not reported = 358â€™077
    - White = 1â€™790â€™496
- Followup state:
    - Alive = 1â€™452â€™573
    - Dead = 720â€™440
    - Not reported = 3â€™112
- Followup time [months]:
    - Min = 0; Median = 28.0; Mean = 40.3; Max = 369.0; NAs = 448â€™942
- Cancer types = 181 types
- Stage = 17 Levels
- Tumor type:
    - Additional - new primary = 166
    - Metastatic = 299â€™149
    - Primary Blood derived cancer - peripheral blood = 516
    - Primary tumor = 2â€™225â€™671
    - Recurrent tumor = 6â€™081